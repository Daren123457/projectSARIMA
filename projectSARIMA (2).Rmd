---
title: "ProjectSARIMA" 
output:
  html_document: default
  pdf_document: default
date: "2022-11-16"
---

#```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
#```

# 1. Load Packages/Library
```{r}
# masukkan semua library yang dibutuhkan disini atau bertambah sesuai dengan kebutuhan, misalnya
library(dplyr) #library digunakan untuk manipulasi data
library(ggplot2) #library digunakan untuk visualiasi data
library(lubridate) #library digunakan untuk mengatur dan mengubah data berbentuk tanggal
library(tidyverse) #library digunakan untuk membantu kegiatan data analysis, dimana didalamnya juga termasuk library dplyr dan ggplot2 
library(tseries) #library untuk membantu kegiatan analysis untuk data yang bersifat time series 


# library untuk membagi dataset
library(caret)
# library untuk model SARIMA
library (forecast)
#library yang membantu dalam kegiatan deskripsi statistik
library (descr)
#library yang membantu pengecekan model regresi linear
library(lmtest)
```




# 2. Obtain Data
```{r}
Data.SPKU <- read.csv("C:/Users/suria/Downloads/Tugas Akhir/Bab 3/Data SPKU.csv")
```
Kita akan menggunakan perintah read.csv untuk mengimport dataset yang akan digunakan dalam penelitian nantinya

# 3. Scrub Data
## a. Melihat Summary data
```{r}
# your code
glimpse(Data.SPKU)
```
Dengan menggunakan perintah glimpse kita dapat melihat bahwa pada dataset ISPU masih memiliki data kosong(missing value) serta tipe data yang juga salah pada variabel tanggal serta beberapa variabel lainnya


## b. Mengubah tipe data variabel
```{r}
Data.SPKU <- Data.SPKU %>%
  mutate(Tanggal = lubridate::mdy(Tanggal))

glimpse(Data.SPKU)
```
Perintah diatas merupakan perintah untuk mengubah tipe data dari Tanggal yang awalnya bertipe char menjadi bertipe date agar dapat digunakan dalam peramalan nantinya

```{r}
Data.SPKU$pm10= as.numeric(as.character(Data.SPKU$pm10)) 
Data.SPKU$so2= as.numeric(as.character(Data.SPKU$so2)) 
Data.SPKU$co= as.numeric(as.character(Data.SPKU$co)) 
Data.SPKU$o3= as.numeric(as.character(Data.SPKU$o3)) 
Data.SPKU$no2= as.numeric(as.character(Data.SPKU$no2)) 
Data.SPKU$Max= as.numeric(as.character(Data.SPKU$Max)) 

```

Selanjutnya adalah perintah untuk mengubah tipe data dari keenam variabel yaitu pm10, so2, co, o3, no2, dan Max yang awalnya bertipe char menjadi bertipe numeric


```{r}
glimpse(Data.SPKU)
```
Dapat dilihat sekarang tipe data yang ada saat ini sudah berubah dari yang awalnya bertipe char sudah menjadi date dan juga double pada dataset yang kita gunakan

## c. Membersihkan data yang Missing Value
```{r}
# your code
colSums(is.na(Data.SPKU))
```
Perintah diatas merupakan perintah yang digunakan untuk melihat data yang tidak memiliki nilai(missing value). Data yang tidak ada nilainya ini harus kita hapus agar nantinya tidak mempengaruhi hasil dari peramalan.

```{r}
Data.SPKU <- na.omit(Data.SPKU)
```
Perintah diatas merupakan perintah untuk mengeluarkan data yang tidak memiliki nilai dari dataset supaya nantinya tidak akan mempengaruhi hasil dari peramalan


```{r}
colSums(is.na(Data.SPKU))
```
Setelah kita cek kembali dengan perintah colSums dapat dilihat bahwa sudah tidak ada data yang tidak memiliki nilai(Missing Value) di dalam dataset yang akan kita gunakan nantinya.



```{r}
sum(duplicated(Data.SPKU))
```
Selanjutnya setelah memastikan atribut dari variabel telah sesuai dan tidak ada missing value lagi di dalamnya, akan menggunakan perintah duplicated untuk mengecek apakah di dataset yang kita gunakan masih ada data yang sama/berulang. Dapat dilihat dari hasilnya didapatkan bahwa sudah tidak ada data duplikat di dalam dataset yang digunakan  



Berikut merupakan tampilan dari dataset setelah dilakukan Scrubbing 

```{r}
glimpse(Data.SPKU)
```

# 4. Explore Data
## a. Analisis Deskriptif

Dalam tahapan explore data, pertama-tama kita dapat menggunakan perintah summary() untuk melihat ringkasan dari dataset yang kita gunakan. Ringkasan ini akan sangat berguna untuk menampilkan data statistik yang dapat membantu kita dalam melakukan analisis Deskriptif

```{r}
summary(Data.SPKU)
```

```{r}
tapply(Data.SPKU$pm10, Data.SPKU$Stasiun, summary)
```
```{r}
tapply(Data.SPKU$so2, Data.SPKU$Stasiun, summary)
```
```{r}
tapply(Data.SPKU$co, Data.SPKU$Stasiun, summary)
```
```{r}
tapply(Data.SPKU$o3, Data.SPKU$Stasiun, summary)
```
```{r}
tapply(Data.SPKU$no2, Data.SPKU$Stasiun, summary)
```


Dibawah ini dilakukan pengujian stasioneritas dengan uji Augmented Dickey Fuller (ADF) yang dibantu dengan perintah adf.test() dari package tseries 
```{r}
adf.test(Data.SPKU$pm10)
adf.test(Data.SPKU$so2)
adf.test(Data.SPKU$co)
adf.test(Data.SPKU$o3)
adf.test(Data.SPKU$no2)
adf.test(Data.SPKU$Max)
```
Dapat dilihat dari hasil diatas bahwa keenam variabel memiliki nilai p-value dibawah 0.01 yang mana artinya datanya sudah stasioner karena bernilai dibawah 5% atau 0.05



## b. Visualisasi Data
### b.1 Visualisasi Data Partikulat Polusi Udara

Dibawah ini merupakan grafik yang menggambarkan nilai dari data variabel partikulat polusi udara dengan tanggal pada kelima stasiun di Jakarta

```{r}
ggplot(data = Data.SPKU) + 
  geom_line(mapping = aes(x = Tanggal, y = pm10, color = Stasiun))+
labs(title = "Grafik pm10")
```
Pada grafik pertama yang menggambarkan data pm10 ini dapat dilihat secara umum data partikulat pm10 yang direkam tertinggi berada pada Stasiun DKI4 dengan nilai tertinggi berada pada akhir tahun 2021 sedangkan nilai terendah berada pada Stasiun DKI3 pada akhir tahun 2017


```{r}
ggplot(data = Data.SPKU) + 
  geom_line(mapping = aes(x = Tanggal, y = so2, color = Stasiun))+
labs(title = "Grafik so2")
```
Pada grafik kedua yang menggambarkan data so2 ini dapat dilihat secara umum data partikulat so2 yang direkam tertinggi berada pada Stasiun DKI3 dengan nilai tertinggi berada pada akhir tahun 2020 sedangkan nilai terendah berada pada Stasiun DKI2 pada awal tahun 2016

```{r}
ggplot(data = Data.SPKU) + 
  geom_line(mapping = aes(x = Tanggal, y = co, color = Stasiun))+
labs(title = "Grafik co")
```
Pada grafik ketiga yang menggambarkan data co ini dapat dilihat secara umum data partikulat co yang direkam tertinggi berada pada Stasiun DKI5 dengan nilai tertinggi berada pada akhir tahun 2020 sedangkan nilai terendah berada pada Stasiun DKI5 pada akhir triwulan pertama pada tahun 2017

```{r}
ggplot(data = Data.SPKU) + 
  geom_line(mapping = aes(x = Tanggal, y = o3, color = Stasiun))+
labs(title = "Grafik o3")
```
Pada grafik keempat yang menggambarkan data o3 ini dapat dilihat secara umum data partikulat o3 yang direkam tertinggi berada pada Stasiun DKI5 dengan nilai tertinggi berada pada akhir triwulan pertama pada tahun 2019 sedangkan nilai terendah berada pada Stasiun DKI5 pada awal triwulan ketiga pada tahun 2020

```{r}
ggplot(data = Data.SPKU) + 
  geom_line(mapping = aes(x = Tanggal, y = no2, color = Stasiun))+
labs(title = "Grafik no2")
```
Pada grafik kelima yang menggambarkan data no2 ini dapat dilihat secara umum data partikulat no2 yang direkam tertinggi berada pada Stasiun DKI2 dengan nilai tertinggi berada pada akhir tahun 2020 sedangkan untuk nilai terendah terbagi merata pada kelima Stasiun dari awal tahun 2016 hingga akhir tahun 2018

```{r}
ggplot(data = Data.SPKU) + 
  geom_line(mapping = aes(x = Tanggal, y = Max, color = Stasiun))+
labs(title = "Grafik Max")
```
Pada grafik keenam yang menggambarkan data Max dari keseluruhan partikulat ini dapat dilihat secara umum data tertinggi yang direkam terdapat pada Stasiun DKI5 di tahun 2019 sedangkan nilai terendah berada pada Stasiun DKI4 pada awal triwulan ketiga tahun 2020



### b.2 Visualisasi Data PM10 berdasar salah satu Stasiun

Sebelum melakukan visualisasi terpisah antara tiap stasiun, untuk merapikan tampilan dari grafik nantinya terlebih dahulu buat vector yang akan digunakan untuk mempersingkat nama stasiun yang akan digunakan menjadi label 
```{r}
Nama_Stasiun <- c(
                    `DKI1 (Bunderan HI)` = "DKI 1",
                    `DKI2 (Kelapa Gading)` = "DKI 2",
                    `DKI3 (Jagakarsa)` = "DKI 3",
                    `DKI4 (Lubang Buaya)` = "DKI 4",
                    `DKI5 (Kebon Jeruk)`="DKI 5"
                    )
```


Dibawah ini merupakan tampilan grafik partikulat pm10 yang dipisahkan berdasarkan berdasarkan stasiun perekaman data tersebut. 
```{r}
ggplot(Data.SPKU, aes(x=Tanggal, y=pm10, group=Stasiun)) + 
  geom_line(aes())+ facet_grid(Stasiun ~ ., scales='free', labeller = as_labeller(Nama_Stasiun))
```

Dibawah ini merupakan tampilan grafik partikulat so2 yang dipisahkan berdasarkan berdasarkan stasiun perekaman data tersebut. 
```{r}
ggplot(Data.SPKU, aes(x=Tanggal, y=so2, group=Stasiun)) + 
  geom_line(aes())+ facet_grid(Stasiun ~ ., scales='free', labeller = as_labeller(Nama_Stasiun))
```

Dibawah ini merupakan tampilan grafik partikulat co yang dipisahkan berdasarkan berdasarkan stasiun perekaman data tersebut. 
```{r}
ggplot(Data.SPKU, aes(x=Tanggal, y=co, group=Stasiun)) + 
  geom_line(aes())+ facet_grid(Stasiun ~ ., scales='free', labeller = as_labeller(Nama_Stasiun))
```

Dibawah ini merupakan tampilan grafik partikulat o3 yang dipisahkan berdasarkan berdasarkan stasiun perekaman data tersebut. 
```{r}
ggplot(Data.SPKU, aes(x=Tanggal, y=o3, group=Stasiun)) + 
  geom_line(aes())+ facet_grid(Stasiun ~ ., scales='free', labeller = as_labeller(Nama_Stasiun))
```

Dibawah ini merupakan tampilan grafik partikulat no2 yang dipisahkan berdasarkan berdasarkan stasiun perekaman data tersebut. 
```{r}
ggplot(Data.SPKU, aes(x=Tanggal, y=no2, group=Stasiun)) + 
  geom_line(aes())+ facet_grid(Stasiun ~ ., scales='free', labeller = as_labeller(Nama_Stasiun))
```

Dibawah ini merupakan tampilan grafik partikulat Max yang dipisahkan berdasarkan berdasarkan stasiun perekaman data tersebut. 
```{r}
ggplot(Data.SPKU, aes(x=Tanggal, y=Max, group=Stasiun)) + 
  geom_line(aes())+ facet_grid(Stasiun ~ ., scales='free', labeller = as_labeller(Nama_Stasiun))
```





```{r}
pm10tot <- Data.SPKU %>% 
  mutate(first_date_month = floor_date(Tanggal, unit = "month")) %>% 
  group_by(first_date_month) %>% 
  summarise(jumlahPM10 = sum (pm10))
pm10tot
```
```{r}
so2tot <- Data.SPKU %>% 
  mutate(first_date_month = floor_date(Tanggal, unit = "month")) %>% 
  group_by(first_date_month) %>% 
  summarise(jumlahSO2 = sum (so2))
so2tot
```

```{r}
cotot <- Data.SPKU %>% 
  mutate(first_date_month = floor_date(Tanggal, unit = "month")) %>% 
  group_by(first_date_month) %>% 
  summarise(jumlahCO = sum (co))
cotot
```

```{r}
o3tot <- Data.SPKU %>% 
  mutate(first_date_month = floor_date(Tanggal, unit = "month")) %>% 
  group_by(first_date_month) %>% 
  summarise(jumlahO3 = sum (o3))
o3tot
```

```{r}
no2tot <- Data.SPKU %>% 
  mutate(first_date_month = floor_date(Tanggal, unit = "month")) %>% 
  group_by(first_date_month) %>% 
  summarise(jumlahNO2 = sum (no2))
no2tot
```



```{r}
ggplot(data = pm10tot, aes(x = first_date_month, y = jumlahPM10, color = "PM10")) +
geom_line() +
geom_line(data = cotot, aes(x = first_date_month, y = jumlahCO, color = "CO")) +
geom_line(data = o3tot, aes(x = first_date_month, y = jumlahO3, color = "O3")) +
geom_line(data = so2tot, aes(x = first_date_month, y = jumlahSO2, color = "SO2")) +
geom_line(data = no2tot, aes(x = first_date_month, y = jumlahNO2, color = "NO2")) +
labs(title = "Jumlah Partikel Polusi Udara per Bulan",
x = "Tahun",
y = "Jumlah Partikel (μg/m3)", 
subtitle = "Data terakhir 31 Desember 2021") +
theme_minimal() +
scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
scale_color_manual(values = c("#0e8eff", "#0e0700", "#d19f00", "#fff80e", "#30e97f"),
labels = c("PM10", "CO", "O3","SO2", "NO2")) 
```

Berdasarkan Gambar diatas bisa dilihat bahwa, rata-rata tingkat O3 dan
SO2 relatif lebih tinggi dibandingkan dengan 3 partikel yang lainnya.





```{r}
pm10 <- Data.SPKU %>% 
  ggplot(aes(x = Tanggal, y = pm10)) +
  geom_point(color = "tomato3", group=1) + 
  labs( 
    title = "Jumlah PM10 per Hari", 
    subtitle = "ISPU Jakarta", 
    caption = "Roni Yunis", 
    x = "Tahun", 
    y = "Jumlah" 
  ) +
  theme_minimal()
pm10
```




```{r}
ggplot(data = Data.SPKU, aes(x = Tanggal, y = pm10, color = Kategori)) +
  geom_line() +
  labs(title = "Jumlah PM10 Berdasarkan Kategori", 
       x = "Tanggal", 
       y = "Partikel PM10 (μg/m3)") +
  scale_color_manual(values = c("#0e8eff", "#0e0700", "#d19f00", "#fff80e"), 
                     labels = c("Baik", "Sangat Tidak Sehat", "Sedang", "Tidak Sehat")) +
  annotate("text", 
           x = max(Data.SPKU$Tanggal), 
           y = mean(Data.SPKU$pm10), label = "PM10") +
  theme_minimal()
  
```
```{r}
# Tingkat SO2 per Weekday
ggplot(data = Data.SPKU, aes(x = Tanggal, y = so2,  fill=Stasiun)) +
  geom_col() +
  labs(title = "Tingkat SO2 Per Minggu") + # dari hari Senin s/d Minggu
  theme_minimal()
```


```{r}
df_dki_4 <- subset(Data.SPKU, Stasiun == "DKI4 (Lubang Buaya)")
```


```{r}
df_dki_4 <- df_dki_4 %>% 
  mutate(year = year(Tanggal),
         month = month(Tanggal),
         day = day(Tanggal),
         weekday = wday(Tanggal),
         year_month = format(Tanggal, format = "%Y-%m"))
df_dki_4
```
```{r}
Nama_Minggu <- c(
                    `1` = "Senin",
                    `2` = "Selasa",
                    `3` = "Rabu",
                    `4` = "Kamis",
                    `5` = "Jumat",
                    `6` = "Sabtu",
                    `7` = "Minggu"
                    )

Nama_Bulan <- c(
                    `1` = "Januari",
                    `2` = "Februari",
                    `3` = "Maret",
                    `4` = "April",
                    `5` = "Mei",
                    `6` = "Juni",
                    `7` = "Juli",
                    `8` = "Agustus",
                    `9` = "September",
                    `10` = "Oktober",
                    `11` = "November",
                    `12` = "Desember"
                    )
```

```{r}
# Tingkat SO2 per Weekday
ggplot(data = df_dki_4, aes(x = weekday, y = so2,  fill=factor(weekday)))+scale_fill_identity("Weekday", labels = Nama_Minggu, breaks = 1:7,
  guide = "legend") +
  geom_col() +
  labs(title = "Tingkat SO2 Per Minggu") + # dari hari Senin s/d Minggu
  theme_minimal()+ scale_x_continuous(breaks = 1:7,
                     labels = Nama_Minggu)
```

Tingkat jumlah partikel SO2 yang paling tinggi sepanjang minggu adalah
dihari Sabtu=6 dan Minggu=7


```{r}
# Tingkat SO2 per Month
ggplot(data = df_dki_4, aes(x = month, y = so2,  fill=factor(month)))+scale_fill_identity("Month", labels = Nama_Bulan, breaks = 1:12,
  guide = "legend") +
  geom_col() +
  labs(title = "Tingkat SO2 Per Bulan") + # dari hari Senin s/d Minggu
  theme( axis.text.x = element_text(angle = 45, hjust = 1,size = 10))+ scale_x_continuous(breaks = 1:12,
                     labels = Nama_Bulan)
```


```{r}
# Tingkat SO2 per month
ggplot(data = df_dki_4, aes(x = month, y = so2, col=month, fill=month)) +
  geom_col() + 
  labs(title = "Tingkat SO2 Per Bulan") + # dari bulan Januari s/d Desember
  theme_minimal()
```

Tingkat jumlah partikel SO2 yang paling rendah ada pada bulan 2 dan
paling tinggi pada bulan 11





```{r, fig.width=10,fig.height=4}
# Tingkat SO2 per Tahun



ggplot(data = df_dki_4, aes(x = year_month, y = so2)) +
  geom_boxplot() +
  labs(title = "Tingkat SO2 per Tahun") +
  theme( axis.text.x = element_text(angle = 45, hjust = 1,size = 11)) 

```


Pola partikel SO2 per bulan tampaknya tidak sama setiap tahunnya.













Note: Bagian ini bisa disesuaikan dengan kebutuhan ekplorasi. jadi poin2 dari visualiasi bisa ditambah berdasarkan kebutuhan

```{r}
kpss.test(Data.SPKU$pm10)
kpss.test(Data.SPKU$so2)
kpss.test(Data.SPKU$co)
kpss.test(Data.SPKU$o3)
kpss.test(Data.SPKU$no2)
```
```{r}
acf(Data.SPKU$pm10, lag.max= 36)
pacf(Data.SPKU$pm10, lag.max= 36)
```



















# 4. Model
Definisikan model prediksi yang akan dilakukan berdasarkan metode yg digunakan LSTM/Prophet/SARIMA

## a. Model Prediksi PM10


Pengujian akan dilakukan pada data df_dki_4 dengan menggunakan uji
Augmented Dickey-Fuller (ADF) dan Kwiatkowski Phillips Schmidt Shin
(KPSS). ADF Test Test ini digunakan untuk memahami apakah deret tersebut
stationer atau tidak. Ada 2 hipotesis yang bisa dikembangkan. H0: deret
waktu tidak stationer dan memiliki beberapa struktur tergantung waktu
*H1: deret waktu stationer dan tidak memiliki beberapa struktur
tergantung waktu* dengan nilai p-value \< 0,05 sehingga HO ditolak, H1
diterima

KPSS test H0 dan H1 untuk uji KPSS berlawanan dengan uji ADF, sehingga
hipotesis dalam KPSS adalah H0: deret tren stationer *H1: deret tren
tidak stationer* dengan nilai p-value \< 0,05 sehingga HO diterima, H1
ditolak

```{r}
adf.test(Data.SPKU$pm10)
```

```{r}
kpss.test(Data.SPKU$pm10, null = "Level")
```

```{r}
#differensiasi data_so2 pada stasiun DKI4
Data.SPKU_diff <- diff(Data.SPKU$pm10)
#dropna dari data yang sudah di-differensiasi
Data.SPKU_diff <- Data.SPKU_diff[!is.na(Data.SPKU_diff)]
```

```{r}
#plot data yang sudah di-differensiasi dan di-dropna
ggplot(data.frame(date = 1:length(Data.SPKU_diff), value = Data.SPKU_diff), aes(x = date, y = value)) +
  geom_line(color = "blue") +
  ggtitle("Stationary timeseries")+
  theme(plot.title = element_text(hjust = 0.5))+
  scale_x_continuous(name = "Hari",
                     breaks = seq(0, length(Data.SPKU_diff), by = 365))+ #periode 365 hari
  scale_y_continuous(name = "Nilai")+
  theme(axis.text.x=element_text(angle=60,hjust=1))+
  theme_minimal()
```

Berdasarkan hasil kedua uji ADF dan KPSS bisa disimpulkan nilai p-value
\< 0,05, sehingga bisa disimpulkan bahwa data deret waktu sudah
stationer. Begitu juga dengan hasil visualiasi uji stationer bisa
dilihat bahwa tidak terlihat tren apapun atau perubahan yang jelas dalam
varians sehingga deret waktu sudah stationer.









```{r}
adf.test(df_dki_4$pm10)
```

```{r}
kpss.test(df_dki_4$pm10, null = "Level")
```

```{r}
#differensiasi data_so2 pada stasiun DKI4
df_dki_4_diff <- diff(df_dki_4$pm10)
#dropna dari data yang sudah di-differensiasi
df_dki_4_diff <- df_dki_4_diff[!is.na(df_dki_4_diff)]
```

```{r}
#plot data yang sudah di-differensiasi dan di-dropna
ggplot(data.frame(date = 1:length(df_dki_4_diff), value = df_dki_4_diff), aes(x = date, y = value)) +
  geom_line(color = "blue") +
  ggtitle("Stationary timeseries")+
  theme(plot.title = element_text(hjust = 0.5))+
  scale_x_continuous(name = "Hari",
                     breaks = seq(0, length(df_dki_4_diff), by = 365))+ #periode 365 hari
  scale_y_continuous(name = "Nilai")+
  theme(axis.text.x=element_text(angle=60,hjust=1))+
  theme_minimal()
```

Berdasarkan hasil kedua uji ADF dan KPSS bisa disimpulkan nilai p-value
\< 0,05, sehingga bisa disimpulkan bahwa data deret waktu sudah
stationer. Begitu juga dengan hasil visualiasi uji stationer bisa
dilihat bahwa tidak terlihat tren apapun atau perubahan yang jelas dalam
varians sehingga deret waktu sudah stationer.


### i.Data Dekomposisi

```{r}
decom_ts <- ts(data = Data.SPKU$pm10, start = c(2016,1), end = c(2021,12), frequency = 12)
```

```{r}
# Classical Decomposition
decom_ts %>% decompose(type = "multiplicative") %>%
  autoplot() + xlab("Year") +
  ggtitle("Multiplicative Decomposition of PM10")
```

```{r}
decom_ts %>% decompose(type = "additive") %>%
  autoplot() + xlab("Year") +
  ggtitle("Additive Decomposition of PM10")
```

```{r}
ts_decom <- decompose(decom_ts)
```

```{r}
ts_decom_table <- data.frame(seasonal = ts_decom$seasonal, trend = ts_decom$trend, random = ts_decom$random)
ts_decom_table <- na.omit(ts_decom_table)
descr(ts_decom_table)
head(ts_decom_table)
```

```{r}
ts_decom$seasonal
```

```{r}
plot(ts_decom$seasonal)
```

```{r}
ts_decom$figure
```

```{r}
plot(ts_decom$figure,
     type = 'b',
     xlab = 'Month',
     ylab = 'Seasonality Index',
     col = 'blue',
     las = 2
)
```

```{r}
#adjustment decomposition data
ts_decom_adj <- decom_ts - ts_decom$seasonal
plot(ts_decom_adj)
```

```{r}
ts_decom_adj
```

```{r}
descr(ts_decom_adj)
```

```{r}
str(ts_decom_adj)
```

```{r}
df_data <- as.data.frame(ts_decom_adj)
df_data
```





```{r}
# Konversi data menjadi data time series menggunakan data dekomposisi time series 
dataset <- decom_ts
plot(dataset)
ggtsdisplay(dataset)
```

```{r}
BoxCox.lambda(dataset)
```

```{r}
# Membagi data menjadi data latih dan data uji
data_train_sarima <- head(dataset, 5*12) # ambil data 5 tahun 2016-2020
data_test_sarima <- tail(dataset, length(dataset)-length(data_train_sarima)) #ambil data 1 tahun terakhir
data_train_sarima %>% 
  decompose() %>% 
  autoplot()
```

```{r}
plot(data_train_sarima)
```

```{r}
length(data_train_sarima)
length(data_test_sarima)
```

### ii. Mengidentifikasi Diferensi

#### a. Mengidentifikasi Diferensi musiman order 1

```{r}
data_train_sarima_ds <- diff(data_train_sarima, differences = 1, lag = 12)
adf.test(data_train_sarima_ds)
```

#Dari hasil diatas bisa disimpulkan bahwa data belum stationer karena nilai p-value \> 0,05 yaitu sebesar 0,4503.

#### b. Mengidentifikasi Diferensi non-musiman order 1

```{r}
data_train_sarima_dss <- diff(data_train_sarima_ds, differences = 1)
adf.test(data_train_sarima_dss)
```

Dari hasil diatas bisa disimpulkan bahwa data sudah stationer karena
nilai p-value \< 0,05 yaitu sebesar 0,01.

### iii. Mengidentifikasi kemungkinan model yang tepat

```{r}
par(mfrow = c(2,1))
acf(data_train_sarima_dss, lag.max = 36)
pacf(data_train_sarima_dss, lag.max = 36)
```

```{r}
data_train_sarima_dss
```

### iv. Fit Model

Menentukan model prediksi yang terbaik yang dapat dilihat dari nilai
performansi Akaike Information Criteria (AIC) dan nilai signifikan
(p-value). Model yang lebih baik akan memiliki nilai AIC yang lebih
rendah

#### a. Fit Model 1


```{r}
# Fit Model 1
fitmodel1 <- Arima (data_train_sarima_dss,
                    order = c(2,2,0),
                    seasonal = c(0,0,1),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel1)
checkresiduals(fitmodel1)
ggtsdisplay(fitmodel1$residuals)
summary(fitmodel1)
```

```{r}
Box.test(residuals(fitmodel1), lag = 12, type = "Ljung-Box")
```

Berdasarkan hasil diatas bisa dilihat bahwa, semua nilai signifikan.
Secara keseluruhan dari model sudah cukup signifikan dengan nilai
p-value 0.0005798 dimana nilai signifikan \< 0,05 dan nilai AIC =
453.4. Sekarang kita akan lakukan fit model yang kedua dengan tujuan
untuk mendapatkan nilai yang lebih baik.

#### b. Fit Model 2

```{r}
# Fit Model 2
fitmodel2 <- Arima (data_train_sarima_dss,
                    order = c(2,2,1),
                    seasonal = c(0,0,1),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel2)
checkresiduals(fitmodel2)
ggtsdisplay(fitmodel2$residuals)
summary(fitmodel2)
```

```{r}
Box.test(residuals(fitmodel2), lag = 12, type = "Ljung-Box")
```

Berdasarkan fit model yang ke 2 didapatkan bahwa secara keseluruhan
model sudah signitifan dengan nilai p-value 0.0008291 dimana nilai
signifikan \< 0,05 dan nilai AIC 430.87. Kita akan lanjutkan melakukan
fit model yang ke 3.

#### c. Fit Model 3

```{r}
# Fit Model 3
fitmodel3 <- Arima (data_train_sarima_dss,
                    order = c(2,2,1),
                    seasonal = c(0,1,1),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel3)
checkresiduals(fitmodel3)
ggtsdisplay(fitmodel3$residuals)
summary(fitmodel3)
```

```{r}
Box.test(residuals(fitmodel3), lag = 12, type = "Ljung-Box")
```

Berdasarkan fit model yang ke 3 didapatkan bahwa secara keseluruhan
model sudah signifikan dengan nilai p-value 0.001457 dimana nilai
signifikan \< 0,05 dan nilai AIC = 352,86.

#### d. Menentukan model terbaik dengan auto.arima

```{r}
# Menentukan model terbaik
modelautoarima_pm10 <- auto.arima(
  data_train_sarima_dss,
  stepwise = FALSE,
  approximation = FALSE,
  trace = TRUE)
modelautoarima_pm10
```

```{r}
Box.test(residuals(modelautoarima_pm10), lag = 12, type = "Ljung-Box")
```

#### e. Fit Model 4
```{r}
# Fit Model 4
fitmodel4 <- Arima (data_train_sarima_dss,
                    order = c(2,1,1),
                    seasonal = c(2,1,0),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel4)
checkresiduals(fitmodel4)
ggtsdisplay(fitmodel4$residuals)
summary(fitmodel4)
```

```{r}
Box.test(residuals(fitmodel4), lag = 12, type = "Ljung-Box")
```
Berdasarkan fit model yang ke 4 didapatkan bahwa secara keseluruhan
model sudah signifikan dengan nilai p-value 0.01116 dimana nilai
signifikan \< 0,05 dan nilai AIC = 346.28.


#### f. Fit Model 5
```{r}
# Fit Model 5
fitmodel5 <- Arima (data_train_sarima_dss,
                    order = c(2,0,1),
                    seasonal = c(2,1,0),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel5)
checkresiduals(fitmodel5)
ggtsdisplay(fitmodel5$residuals)
summary(fitmodel5)
```
```{r}
Box.test(residuals(fitmodel5), lag = 12, type = "Ljung-Box")
```
Berdasarkan fit model yang ke 5 didapatkan bahwa secara keseluruhan
model sudah signifikan dengan nilai p-value 0.04801 dimana nilai
signifikan \< 0,05 dan nilai AIC = 324.17.


```{r}
hasil_df <- data.frame(
  id = c(1:6),
  Model = c("Model1(2,2,0)(0,0,1)", "Model2(2,2,1)(0,0,1)", "Model3(2,2,1)(0,1,1)", "Model4(2,1,1)(2,1,0)", "Model5(2,0,1)(2,1,0)","AutoArima(2,0,2)(1,0,0)"),
  AIC = c(fitmodel1$aic, fitmodel2$aic, fitmodel3$aic, fitmodel4$aic, fitmodel5$aic, modelautoarima_pm10$aic),
  BIC = c(fitmodel1$bic, fitmodel2$bic, fitmodel3$bic, fitmodel4$bic, fitmodel4$bic, modelautoarima_pm10$bic),
   stringsAsFactors = FALSE
)
hasil_df
```

Berdasarkan modelautoarima didapatkan model (2,0,2)(1,0,0) dengan nilai
AIC = 394.21. Sehingga dapat disimpulkan bahwa performa fitmodel1 dengan
nilai AIC = 453.38, fitmodel2 dengan nilai AIC = 430.87, dan fitmodel3
dengan nilai AIC = 352.86, dan fitmodel4 dengan nilai AIC 346.28, dan fitmodel5 dengan nilai AIC 324.17.
Berdasarkan keenam model tersebut, maka perfomansi model *fitmodel5*
yang terbaik yaitu model (2,1,1)(2,1,0) dengan nilai AIC sebesar 346.28
dan nilai p-value untuk keseluruhan signitifkan.

### v. Forecasting dengan data latih

```{r}
# Menggunakan fitmodel3
fcast <- forecast(fitmodel5, h=12)
fcast
autoplot(fcast)
```

```{r}
# membuat prediksi untuk data uji dengan menggunakan model terbaik
predictSarima <- predict(fcast, data_test_sarima)
autoplot(predictSarima)
```

```{r}
# visualisasi hasil forecast dari model multiplicative
data_test_sarima %>% 
  autoplot()+
  autolayer(modelautoarima_pm10$fitted, series = "Auto-Arima(2,0,1)(0,0,1)")+
  autolayer(data_test_sarima, series = "data test") +
  autolayer(fitmodel1$fitted, series = "Model-1(2,2,0)(0,0,1)")+
  autolayer(fitmodel2$fitted, series = "Model-2(2,2,1)(0,0,1)")+
  autolayer(fitmodel3$fitted, series = "Model-3(2,2,1)(0,1,1)")+
  autolayer(fitmodel4$fitted, series = "Model-4(2,1,1)(2,1,0)")+
  autolayer(fitmodel5$fitted, series = "Model-5(2,0,1)(2,1,0)")+
  autolayer(predictSarima$mean, series = "forecast")
```

### vi. Evaluasi Model

```{r}
# Mean squared error (MSE)
MSESarima <- mean((data_test_sarima - predictSarima$mean)^2)
MSESarima
```

```{r}
# Root mean squared error (RMSE)
RMSESarima <- sqrt(MSESarima)
RMSESarima
```

```{r}
# Mean absolute error (MAE)
MAESarima <- mean(abs(data_test_sarima - predictSarima$mean))
MAESarima
```

```{r}
# Mean absolute percentage error (MAPE)
MAPESarima <- mean(abs(data_test_sarima - predictSarima$mean) / data_test_sarima)
MAPESarima
```








## b. Model Prediksi SO2


Pengujian akan dilakukan pada data df_dki_4 dengan menggunakan uji
Augmented Dickey-Fuller (ADF) dan Kwiatkowski Phillips Schmidt Shin
(KPSS). ADF Test Test ini digunakan untuk memahami apakah deret tersebut
stationer atau tidak. Ada 2 hipotesis yang bisa dikembangkan. H0: deret
waktu tidak stationer dan memiliki beberapa struktur tergantung waktu
*H1: deret waktu stationer dan tidak memiliki beberapa struktur
tergantung waktu* dengan nilai p-value \< 0,05 sehingga HO ditolak, H1
diterima

KPSS test H0 dan H1 untuk uji KPSS berlawanan dengan uji ADF, sehingga
hipotesis dalam KPSS adalah H0: deret tren stationer *H1: deret tren
tidak stationer* dengan nilai p-value \< 0,05 sehingga HO diterima, H1
ditolak

```{r}
adf.test(df_dki_4$so2)
```

```{r}
kpss.test(df_dki_4$so2, null = "Level")
```

```{r}
#differensiasi data_so2 pada stasiun DKI4
df_dki_4_diff_so2 <- diff(df_dki_4$so2)
#dropna dari data yang sudah di-differensiasi
df_dki_4_diff_so2 <- df_dki_4_diff_so2[!is.na(df_dki_4_diff_so2)]
```

```{r}
#plot data yang sudah di-differensiasi dan di-dropna
ggplot(data.frame(date = 1:length(df_dki_4_diff_so2), value = df_dki_4_diff_so2), aes(x = date, y = value)) +
  geom_line(color = "blue") +
  ggtitle("Stationary timeseries")+
  theme(plot.title = element_text(hjust = 0.5))+
  scale_x_continuous(name = "Hari",
                     breaks = seq(0, length(df_dki_4_diff_so2), by = 365))+ #periode 365 hari
  scale_y_continuous(name = "Nilai")+
  theme(axis.text.x=element_text(angle=60,hjust=1))+
  theme_minimal()
```

Berdasarkan hasil kedua uji ADF dan KPSS bisa disimpulkan nilai p-value
\< 0,05, sehingga bisa disimpulkan bahwa data deret waktu sudah
stationer. Begitu juga dengan hasil visualiasi uji stationer bisa
dilihat bahwa tidak terlihat tren apapun atau perubahan yang jelas dalam
varians sehingga deret waktu sudah stationer.

### i. Data Dekomposisi

```{r}
decom_ts_so2 <- ts(data = Data.SPKU$so2, start = c(2016,1), end = c(2021,12), frequency = 12)
```

```{r}
# Classical Decomposition
decom_ts_so2 %>% decompose(type = "multiplicative") %>%
  autoplot() + xlab("Year") +
  ggtitle("Multiplicative Decomposition of SO2")
```

```{r}
decom_ts_so2 %>% decompose(type = "additive") %>%
  autoplot() + xlab("Year") +
  ggtitle("Additive Decomposition of SO2")
```

```{r}
ts_decom_so2 <- decompose(decom_ts_so2)
```

```{r}
ts_decom_table_so2 <- data.frame(seasonal = ts_decom_so2$seasonal, trend = ts_decom_so2$trend, random = ts_decom_so2$random)
ts_decom_table_so2 <- na.omit(ts_decom_table_so2)
descr(ts_decom_table_so2)
head(ts_decom_table_so2)
```

```{r}
ts_decom_so2$seasonal
```

```{r}
plot(ts_decom_so2$seasonal)
```

```{r}
ts_decom_so2$figure
```

```{r}
plot(ts_decom_so2$figure,
     type = 'b',
     xlab = 'Month',
     ylab = 'Seasonality Index',
     col = 'blue',
     las = 2
)
```

```{r}
#adjustment decomposition data
ts_decom_adj_so2 <- decom_ts_so2 - ts_decom_so2$seasonal
plot(ts_decom_adj_so2)
```

```{r}
ts_decom_adj_so2
```

```{r}
descr(ts_decom_adj_so2)
```

```{r}
str(ts_decom_adj_so2)
```

```{r}
df_data_so2 <- as.data.frame(ts_decom_adj_so2)
df_data_so2
```



```{r}
# Konversi data menjadi data time series menggunakan data dekomposisi time series 
dataset_so2 <- decom_ts_so2
plot(dataset_so2)
ggtsdisplay(dataset_so2)
```

```{r}
BoxCox.lambda(dataset_so2)
```

```{r}
# Membagi data menjadi data latih dan data uji
data_train_sarima_so2 <- head(dataset_so2, 5*12) # ambil data 5 tahun 2016-2020
data_test_sarima_so2 <- tail(dataset_so2, length(dataset_so2)-length(data_train_sarima_so2)) #ambil data 1 tahun terakhir
data_train_sarima_so2 %>% 
  decompose() %>% 
  autoplot()
```

```{r}
plot(data_train_sarima_so2)
```

```{r}
length(data_train_sarima_so2)
length(data_test_sarima_so2)
```

### ii. Mengidentifikasi Diferensi

#### a. Mengidentifikasi Diferensi musiman order 1

```{r}
data_train_sarima_ds_so2 <- diff(data_train_sarima_so2, differences = 1, lag = 12)
adf.test(data_train_sarima_ds_so2)
```

Dari hasil diatas bisa disimpulkan bahwa data belum stationer karena
nilai p-value \> 0,05 yaitu sebesar 0,3379.

#### b. Mengidentifikasi Diferensi non-musiman order 1

```{r}
data_train_sarima_dss_so2 <- diff(data_train_sarima_ds_so2, differences = 1)
adf.test(data_train_sarima_dss_so2)
```

Dari hasil diatas juga bisa disimpulkan bahwa data masih belum stationer karena
nilai p-value \< 0,05 yaitu sebesar 0,3462.

#### c. Mengidentifikasi Diferensi non-musiman order 2
```{r}
data_train_sarima_dss2_so2 <- diff(data_train_sarima_ds_so2, differences = 2)
adf.test(data_train_sarima_dss2_so2)
```
Dari hasil diatas bisa disimpulkan bahwa data sudah stationer karena
nilai p-value \< 0,05 yaitu sebesar 0,01.

### iii. Mengidentifikasi kemungkinan model yang tepat

```{r}
par(mfrow = c(2,1))
acf(data_train_sarima_dss2_so2, lag.max = 36)
pacf(data_train_sarima_dss2_so2, lag.max = 36)
```

```{r}
data_train_sarima_dss2_so2
```

### iv. Fit Model

Menentukan model prediksi yang terbaik yang dapat dilihat dari nilai
performansi Akaike Information Criteria (AIC) dan nilai signifikan
(p-value). Model yang lebih baik akan memiliki nilai AIC yang lebih
rendah

#### a. Fit Model 1



```{r}
# Fit Model 1
fitmodel1_so2 <- Arima (data_train_sarima_dss2_so2,
                    order = c(2,2,0),
                    seasonal = c(0,0,1),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel1_so2)
checkresiduals(fitmodel1_so2)
ggtsdisplay(fitmodel1_so2$residuals)
summary(fitmodel1_so2)
```

```{r}
Box.test(residuals(fitmodel1_so2), lag = 12, type = "Ljung-Box")
```

Berdasarkan hasil diatas bisa dilihat bahwa, semua nilai signifikan.
Secara keseluruhan dari model sudah cukup signifikan dengan nilai
p-value 0.0003372 dimana nilai signifikan \< 0,05 dan nilai AIC =
388.51. Sekarang kita akan lakukan fit model yang kedua dengan tujuan
untuk mendapatkan nilai yang lebih baik.

#### b. Fit Model 2

```{r}
# Fit Model 2
fitmodel2_so2 <- Arima (data_train_sarima_dss2_so2,
                    order = c(2,2,1),
                    seasonal = c(0,0,1),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel2_so2)
checkresiduals(fitmodel2_so2)
ggtsdisplay(fitmodel2_so2$residuals)
summary(fitmodel2_so2)
```

```{r}
Box.test(residuals(fitmodel2_so2), lag = 12, type = "Ljung-Box")
```

Berdasarkan fit model yang ke 2 didapatkan bahwa secara keseluruhan
model sudah signifikan dengan nilai p-value 0.03113 dimana nilai
signifikan \< 0,05 dan nilai AIC 362.36. Kita akan lanjutkan melakukan
fit model yang ke 3.

#### c. Fit Model 3

```{r}
# Fit Model 3
fitmodel3_so2 <- Arima (data_train_sarima_dss2_so2,
                    order = c(2,2,1),
                    seasonal = c(0,1,1),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel3_so2)
checkresiduals(fitmodel3_so2)
ggtsdisplay(fitmodel3_so2$residuals)
summary(fitmodel3_so2)
```

```{r}
Box.test(residuals(fitmodel3_so2), lag = 12, type = "Ljung-Box")
```

Berdasarkan fit model yang ke 3 didapatkan bahwa secara keseluruhan
model sudah signifikan dengan nilai p-value 0.0009631 dimana nilai
signifikan \< 0,05 dan nilai AIC = 311.27.

#### d. Menentukan model terbaik dengan auto.arima

```{r}
# Menentukan model terbaik
modelautoarima_so2 <- auto.arima(
  data_train_sarima_dss2_so2,
  stepwise = FALSE,
  approximation = FALSE,
  trace = TRUE)
modelautoarima_so2
```

```{r}
Box.test(residuals(modelautoarima_so2), lag = 12, type = "Ljung-Box")
```

#### e. Fit Model 4
```{r}
# Fit Model 4
fitmodel4_so2 <- Arima (data_train_sarima_dss2_so2,
                    order = c(2,1,1),
                    seasonal = c(2,1,0),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel4_so2)
checkresiduals(fitmodel4_so2)
ggtsdisplay(fitmodel4_so2$residuals)
summary(fitmodel4_so2)
```

```{r}
Box.test(residuals(fitmodel4_so2), lag = 12, type = "Ljung-Box")
```
Berdasarkan fit model yang ke 4 didapatkan bahwa secara keseluruhan
model sudah signifikan dengan nilai p-value 0.02704 dimana nilai
signifikan \< 0,05 dan nilai AIC = 286.74.


```{r}
hasil_df_so2 <- data.frame(
  id = c(1:5),
  Model = c("Model1(2,2,0)(0,0,1)", "Model2(2,2,1)(0,0,1)", "Model3(2,2,1)(0,1,1)", "Model4(2,1,1)(2,1,0)","AutoArima(1,0,1)(1,0,0)"),
  AIC = c(fitmodel1_so2$aic, fitmodel2_so2$aic, fitmodel3_so2$aic, fitmodel4_so2$aic, modelautoarima_so2$aic),
  BIC = c(fitmodel1_so2$bic, fitmodel2_so2$bic, fitmodel3_so2$bic, fitmodel4_so2$bic, modelautoarima_so2$bic),
   stringsAsFactors = FALSE
)
hasil_df_so2
```

Berdasarkan modelautoarima didapatkan model (2,0,1)(0,0,1) dengan nilai
AIC = 329.97. Sehingga dapat disimpulkan bahwa performa fitmodel1 dengan
nilai AIC = 388.51, fitmodel2 dengan nilai AIC = 362.36 dan fitmodel3
dengan nilai AIC = 311.27, dan fitmodel4 dengan nilai AIC 286.74.
Berdasarkan kelima model tersebut, maka perfomansi model *fitmodel4*
yang terbaik yaitu model (2,1,1)(2,1,0) dengan nilai AIC sebesar 286.74
dan nilai p-value untuk keseluruhan signitifkan.

### v. Forecasting dengan data latih

```{r}
# Menggunakan fitmodel4
fcast_so2 <- forecast(fitmodel4_so2, h=12)
fcast_so2
autoplot(fcast_so2)
```

```{r}
# membuat prediksi untuk data uji dengan menggunakan model terbaik
predictSarima_so2 <- predict(fcast_so2, data_test_sarima_so2)
autoplot(predictSarima_so2)
```

```{r}
# visualisasi hasil forecast dari model multiplicative
data_test_sarima_so2 %>% 
  autoplot()+
  autolayer(modelautoarima_so2$fitted, series = "Auto-Arima(1,0,1)(1,0,0)")+
  autolayer(data_test_sarima_so2, series = "data test") +
  autolayer(fitmodel1_so2$fitted, series = "Model-1(2,2,0)(0,0,1)")+
  autolayer(fitmodel2_so2$fitted, series = "Model-2(2,2,1)(0,0,1)")+
  autolayer(fitmodel3_so2$fitted, series = "Model-3(2,2,1)(0,1,1)")+
  autolayer(fitmodel4_so2$fitted, series = "Model-4(2,1,1)(2,1,0)")+
  autolayer(predictSarima_so2$mean, series = "forecast")
```

### vi. Evaluasi Model

```{r}
# Mean squared error (MSE)
MSESarima_so2 <- mean((data_test_sarima_so2 - predictSarima_so2$mean)^2)
MSESarima_so2
```

```{r}
# Root mean squared error (RMSE)
RMSESarima_so2 <- sqrt(MSESarima_so2)
RMSESarima_so2
```

```{r}
# Mean absolute error (MAE)
MAESarima_so2 <- mean(abs(data_test_sarima_so2 - predictSarima_so2$mean))
MAESarima_so2
```

```{r}
# Mean absolute percentage error (MAPE)
MAPESarima_so2 <- mean(abs(data_test_sarima_so2 - predictSarima_so2$mean) / data_test_sarima_so2)
MAPESarima_so2
```


## c. Model Prediksi CO

Pengujian akan dilakukan pada data df_dki_4 dengan menggunakan uji
Augmented Dickey-Fuller (ADF) dan Kwiatkowski Phillips Schmidt Shin
(KPSS). ADF Test Test ini digunakan untuk memahami apakah deret tersebut
stationer atau tidak. Ada 2 hipotesis yang bisa dikembangkan. H0: deret
waktu tidak stationer dan memiliki beberapa struktur tergantung waktu
*H1: deret waktu stationer dan tidak memiliki beberapa struktur
tergantung waktu* dengan nilai p-value \< 0,05 sehingga HO ditolak, H1
diterima

KPSS test H0 dan H1 untuk uji KPSS berlawanan dengan uji ADF, sehingga
hipotesis dalam KPSS adalah H0: deret tren stationer *H1: deret tren
tidak stationer* dengan nilai p-value \< 0,05 sehingga HO diterima, H1
ditolak

```{r}
adf.test(df_dki_4$co)
```

```{r}
kpss.test(df_dki_4$co, null = "Level")
```

```{r}
#differensiasi data_so2 pada stasiun DKI4
df_dki_4_diff_co <- diff(df_dki_4$co)
#dropna dari data yang sudah di-differensiasi
df_dki_4_diff_co <- df_dki_4_diff_co[!is.na(df_dki_4_diff_co)]
```

```{r}
#plot data yang sudah di-differensiasi dan di-dropna
ggplot(data.frame(date = 1:length(df_dki_4_diff_co), value = df_dki_4_diff_co), aes(x = date, y = value)) +
  geom_line(color = "blue") +
  ggtitle("Stationary timeseries")+
  theme(plot.title = element_text(hjust = 0.5))+
  scale_x_continuous(name = "Hari",
                     breaks = seq(0, length(df_dki_4_diff_co), by = 365))+ #periode 365 hari
  scale_y_continuous(name = "Nilai")+
  theme(axis.text.x=element_text(angle=60,hjust=1))+
  theme_minimal()
```

Berdasarkan hasil kedua uji ADF dan KPSS bisa disimpulkan nilai p-value
\< 0,05, sehingga bisa disimpulkan bahwa data deret waktu sudah
stationer. Begitu juga dengan hasil visualiasi uji stationer bisa
dilihat bahwa tidak terlihat tren apapun atau perubahan yang jelas dalam
varians sehingga deret waktu sudah stationer.

### i. Data Dekomposisi

```{r}
decom_ts_co <- ts(data = Data.SPKU$co, start = c(2016,1), end = c(2021,12), frequency = 12)
```

```{r}
# Classical Decomposition
decom_ts_co %>% decompose(type = "multiplicative") %>%
  autoplot() + xlab("Year") +
  ggtitle("Multiplicative Decomposition of CO")
```

```{r}
decom_ts_co %>% decompose(type = "additive") %>%
  autoplot() + xlab("Year") +
  ggtitle("Additive Decomposition of CO")
```

```{r}
ts_decom_co <- decompose(decom_ts_co)
```

```{r}
ts_decom_table_co <- data.frame(seasonal = ts_decom_co$seasonal, trend = ts_decom_co$trend, random = ts_decom_co$random)
ts_decom_table_co <- na.omit(ts_decom_table_co)
descr(ts_decom_table_co)
head(ts_decom_table_co)
```

```{r}
ts_decom_co$seasonal
```

```{r}
plot(ts_decom_co$seasonal)
```

```{r}
ts_decom_co$figure
```

```{r}
plot(ts_decom_co$figure,
     type = 'b',
     xlab = 'Month',
     ylab = 'Seasonality Index',
     col = 'blue',
     las = 2
)
```

```{r}
#adjustment decomposition data
ts_decom_adj_co <- decom_ts_co - ts_decom_co$seasonal
plot(ts_decom_adj_co)
```

```{r}
ts_decom_adj_co
```

```{r}
descr(ts_decom_adj_co)
```

```{r}
str(ts_decom_adj_co)
```

```{r}
df_data_co <- as.data.frame(ts_decom_adj_co)
df_data_co
```



```{r}
# Konversi data menjadi data time series menggunakan data dekomposisi time series 
dataset_co <- decom_ts_co
plot(dataset_co)
ggtsdisplay(dataset_co)
```

```{r}
BoxCox.lambda(dataset_co)
```

```{r}
# Membagi data menjadi data latih dan data uji
data_train_sarima_co <- head(dataset_co, 5*12) # ambil data 5 tahun 2016-2020
data_test_sarima_co <- tail(dataset_co, length(dataset_co)-length(data_train_sarima_co)) #ambil data 1 tahun terakhir
data_train_sarima_co %>% 
  decompose() %>% 
  autoplot()
```

```{r}
plot(data_train_sarima_co)
```

```{r}
length(data_train_sarima_co)
length(data_test_sarima_co)
```

### ii. Mengidentifikasi Diferensi

#### a. Mengidentifikasi Diferensi musiman order 1

```{r}
data_train_sarima_ds_co <- diff(data_train_sarima_co, differences = 1, lag = 12)
adf.test(data_train_sarima_ds_co)
```

Dari hasil diatas bisa disimpulkan bahwa data belum stationer karena
nilai p-value \> 0,05 yaitu sebesar 0,794.

#### b. Mengidentifikasi Diferensi non-musiman order 1

```{r}
data_train_sarima_dss_co <- diff(data_train_sarima_ds_co, differences = 1)
adf.test(data_train_sarima_dss_co)
```

Dari hasil diatas bisa disimpulkan bahwa data sudah stationer karena
nilai p-value \< 0,05 yaitu sebesar 0,01.


### iii. Mengidentifikasi kemungkinan model yang tepat

```{r}
par(mfrow = c(2,1))
acf(data_train_sarima_dss_co, lag.max = 36)
pacf(data_train_sarima_dss_co, lag.max = 36)
```

```{r}
data_train_sarima_dss_co
```

### iv. Fit Model

Menentukan model prediksi yang terbaik yang dapat dilihat dari nilai
performansi Akaike Information Criteria (AIC) dan nilai signifikan
(p-value). Model yang lebih baik akan memiliki nilai AIC yang lebih
rendah

#### a. Fit Model 1



```{r}
# Fit Model 1
fitmodel1_co <- Arima (data_train_sarima_dss_co,
                    order = c(2,2,0),
                    seasonal = c(0,0,1),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel1_co)
checkresiduals(fitmodel1_co)
ggtsdisplay(fitmodel1_co$residuals)
summary(fitmodel1_co)
```

```{r}
Box.test(residuals(fitmodel1_co), lag = 12, type = "Ljung-Box")
```

Berdasarkan hasil diatas bisa dilihat bahwa, semua nilai signifikan.
Secara keseluruhan dari model sudah cukup signifikan dengan nilai
p-value 0.006336 dimana nilai signifikan \< 0,05 dan nilai AIC =
398.82. Sekarang kita akan lakukan fit model yang kedua dengan tujuan
untuk mendapatkan nilai yang lebih baik.

#### b. Fit Model 2

```{r}
# Fit Model 2
fitmodel2_co <- Arima (data_train_sarima_dss_co,
                    order = c(2,2,1),
                    seasonal = c(0,0,1),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel2_co)
checkresiduals(fitmodel2_co)
ggtsdisplay(fitmodel2_co$residuals)
summary(fitmodel2_co)
```

```{r}
Box.test(residuals(fitmodel2_co), lag = 12, type = "Ljung-Box")
```

Berdasarkan fit model yang ke 2 didapatkan bahwa secara keseluruhan
model sudah signifikan dengan nilai p-value 0.002414 dimana nilai
signifikan \< 0,05 dan nilai AIC 380.51. Kita akan lanjutkan melakukan
fit model yang ke 3.

#### c. Fit Model 3

```{r}
# Fit Model 3
fitmodel3_co <- Arima (data_train_sarima_dss_co,
                    order = c(2,2,1),
                    seasonal = c(0,1,1),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel3_co)
checkresiduals(fitmodel3_co)
ggtsdisplay(fitmodel3_co$residuals)
summary(fitmodel3_co)
```

```{r}
Box.test(residuals(fitmodel3_co), lag = 12, type = "Ljung-Box")
```

Berdasarkan fit model yang ke 3 didapatkan bahwa model belum 
memenuhi taraf signifikasi dengan nilai p-value 0.05722 dimana nilai
signifikan \> 0,05 dan nilai AIC = 323.08.

#### d. Menentukan model terbaik dengan auto.arima

```{r}
# Menentukan model terbaik
modelautoarima_co <- auto.arima(
  data_train_sarima_dss_co,
  stepwise = FALSE,
  approximation = FALSE,
  trace = TRUE)
modelautoarima_co
```

```{r}
Box.test(residuals(modelautoarima_co), lag = 12, type = "Ljung-Box")
```

#### e. Fit Model 4
```{r}
# Fit Model 4
fitmodel4_co <- Arima (data_train_sarima_dss_co,
                    order = c(2,1,1),
                    seasonal = c(2,1,0),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel4_co)
checkresiduals(fitmodel4_co)
ggtsdisplay(fitmodel4_co$residuals)
summary(fitmodel4_co)
```

```{r}
Box.test(residuals(fitmodel4_co), lag = 12, type = "Ljung-Box")
```
Berdasarkan fit model yang ke 4 didapatkan bahwa secara keseluruhan
model sudah signifikan dengan nilai p-value 0.02931 dimana nilai
signifikan \< 0,05 dan nilai AIC = 310.59.


```{r}
hasil_df_co <- data.frame(
  id = c(1:5),
  Model = c("Model1(2,2,0)(0,0,1)", "Model2(2,2,1)(0,0,1)", "Model3(2,2,1)(0,1,1)", "Model4(2,1,1)(2,1,0)","AutoArima(0,0,3)(1,0,0)"),
  AIC = c(fitmodel1_co$aic, fitmodel2_co$aic, fitmodel3_co$aic, fitmodel4_co$aic, modelautoarima_co$aic),
  BIC = c(fitmodel1_co$bic, fitmodel2_co$bic, fitmodel3_co$bic, fitmodel4_co$bic, modelautoarima_co$bic),
   stringsAsFactors = FALSE
)
hasil_df_co
```

Berdasarkan modelautoarima didapatkan model (0,0,3)(1,0,0) dengan nilai
AIC = 364.44. Sehingga dapat disimpulkan bahwa performa fitmodel1 dengan
nilai AIC = 398.82, fitmodel2 dengan nilai AIC = 380.51 dan fitmodel3
dengan nilai AIC = 323.08, dan fitmodel4 dengan nilai AIC 310.59.
Berdasarkan kelima model tersebut, maka perfomansi model *fitmodel4*
yang terbaik yaitu model (2,1,1)(2,1,0) dengan nilai AIC sebesar 310.59
dan nilai p-value untuk keseluruhan signitifkan.

### v. Forecasting dengan data latih

```{r}
# Menggunakan fitmodel4
fcast_co <- forecast(fitmodel4_co, h=12)
fcast_co
autoplot(fcast_co)
```

```{r}
# membuat prediksi untuk data uji dengan menggunakan model terbaik
predictSarima_co <- predict(fcast_co, data_test_sarima_co)
autoplot(predictSarima_co)
```

```{r}
# visualisasi hasil forecast dari model multiplicative
data_test_sarima_co %>% 
  autoplot()+
  autolayer(modelautoarima_co$fitted, series = "Auto-Arima(0,0,3)(1,0,0)")+
  autolayer(data_test_sarima_co, series = "data test") +
  autolayer(fitmodel1_co$fitted, series = "Model-1(2,2,0)(0,0,1)")+
  autolayer(fitmodel2_co$fitted, series = "Model-2(2,2,1)(0,0,1)")+
  autolayer(fitmodel3_co$fitted, series = "Model-3(2,2,1)(0,1,1)")+
  autolayer(fitmodel4_co$fitted, series = "Model-4(2,1,1)(2,1,0)")+
  autolayer(predictSarima_co$mean, series = "forecast")
```

### vi. Evaluasi Model

```{r}
# Mean squared error (MSE)
MSESarima_co <- mean((data_test_sarima_co - predictSarima_co$mean)^2)
MSESarima_co
```

```{r}
# Root mean squared error (RMSE)
RMSESarima_co <- sqrt(MSESarima_co)
RMSESarima_co
```

```{r}
# Mean absolute error (MAE)
MAESarima_co <- mean(abs(data_test_sarima_co - predictSarima_co$mean))
MAESarima_co
```

```{r}
# Mean absolute percentage error (MAPE)
MAPESarima_co <- mean(abs(data_test_sarima_co - predictSarima_co$mean) / data_test_sarima_co)
MAPESarima_co
```



## d. Model Prediksi O3

Pengujian akan dilakukan pada data df_dki_4 dengan menggunakan uji
Augmented Dickey-Fuller (ADF) dan Kwiatkowski Phillips Schmidt Shin
(KPSS). ADF Test Test ini digunakan untuk memahami apakah deret tersebut
stationer atau tidak. Ada 2 hipotesis yang bisa dikembangkan. H0: deret
waktu tidak stationer dan memiliki beberapa struktur tergantung waktu
*H1: deret waktu stationer dan tidak memiliki beberapa struktur
tergantung waktu* dengan nilai p-value \< 0,05 sehingga HO ditolak, H1
diterima

KPSS test H0 dan H1 untuk uji KPSS berlawanan dengan uji ADF, sehingga
hipotesis dalam KPSS adalah H0: deret tren stationer *H1: deret tren
tidak stationer* dengan nilai p-value \< 0,05 sehingga HO diterima, H1
ditolak

```{r}
adf.test(df_dki_4$o3)
```

```{r}
kpss.test(df_dki_4$o3, null = "Level")
```

```{r}
#differensiasi data_so2 pada stasiun DKI4
df_dki_4_diff_o3 <- diff(df_dki_4$o3)
#dropna dari data yang sudah di-differensiasi
df_dki_4_diff_o3 <- df_dki_4_diff_o3[!is.na(df_dki_4_diff_o3)]
```

```{r}
#plot data yang sudah di-differensiasi dan di-dropna
ggplot(data.frame(date = 1:length(df_dki_4_diff_o3), value = df_dki_4_diff_o3), aes(x = date, y = value)) +
  geom_line(color = "blue") +
  ggtitle("Stationary timeseries")+
  theme(plot.title = element_text(hjust = 0.5))+
  scale_x_continuous(name = "Hari",
                     breaks = seq(0, length(df_dki_4_diff_o3), by = 365))+ #periode 365 hari
  scale_y_continuous(name = "Nilai")+
  theme(axis.text.x=element_text(angle=60,hjust=1))+
  theme_minimal()
```

Berdasarkan hasil kedua uji ADF dan KPSS bisa disimpulkan nilai p-value
\< 0,05, sehingga bisa disimpulkan bahwa data deret waktu sudah
stationer. Begitu juga dengan hasil visualiasi uji stationer bisa
dilihat bahwa tidak terlihat tren apapun atau perubahan yang jelas dalam
varians sehingga deret waktu sudah stationer.

### i. Data Dekomposisi

```{r}
decom_ts_o3 <- ts(data = Data.SPKU$o3, start = c(2016,1), end = c(2021,12), frequency = 12)
```

```{r}
# Classical Decomposition
decom_ts_o3 %>% decompose(type = "multiplicative") %>%
  autoplot() + xlab("Year") +
  ggtitle("Multiplicative Decomposition of O3")
```

```{r}
decom_ts_o3 %>% decompose(type = "additive") %>%
  autoplot() + xlab("Year") +
  ggtitle("Additive Decomposition of O3")
```

```{r}
ts_decom_o3 <- decompose(decom_ts_o3)
```

```{r}
ts_decom_table_o3 <- data.frame(seasonal = ts_decom_o3$seasonal, trend = ts_decom_o3$trend, random = ts_decom_o3$random)
ts_decom_table_o3 <- na.omit(ts_decom_table_o3)
descr(ts_decom_table_o3)
head(ts_decom_table_o3)
```

```{r}
ts_decom_o3$seasonal
```

```{r}
plot(ts_decom_o3$seasonal)
```

```{r}
ts_decom_o3$figure
```

```{r}
plot(ts_decom_o3$figure,
     type = 'b',
     xlab = 'Month',
     ylab = 'Seasonality Index',
     col = 'blue',
     las = 2
)
```

```{r}
#adjustment decomposition data
ts_decom_adj_o3 <- decom_ts_o3 - ts_decom_o3$seasonal
plot(ts_decom_adj_o3)
```

```{r}
ts_decom_adj_o3
```

```{r}
descr(ts_decom_adj_o3)
```

```{r}
str(ts_decom_adj_o3)
```

```{r}
df_data_o3 <- as.data.frame(ts_decom_adj_o3)
df_data_o3
```



```{r}
# Konversi data menjadi data time series menggunakan data dekomposisi time series 
dataset_o3 <- decom_ts_o3
plot(dataset_o3)
ggtsdisplay(dataset_o3)
```

```{r}
BoxCox.lambda(dataset_o3)
```

```{r}
# Membagi data menjadi data latih dan data uji
data_train_sarima_o3 <- head(dataset_o3, 5*12) # ambil data 5 tahun 2016-2020
data_test_sarima_o3 <- tail(dataset_o3, length(dataset_o3)-length(data_train_sarima_o3)) #ambil data 1 tahun terakhir
data_train_sarima_o3 %>% 
  decompose() %>% 
  autoplot()
```

```{r}
plot(data_train_sarima_o3)
```

```{r}
length(data_train_sarima_o3)
length(data_test_sarima_o3)
```

### ii. Mengidentifikasi Diferensi

#### a. Mengidentifikasi Diferensi musiman order 1

```{r}
data_train_sarima_ds_o3 <- diff(data_train_sarima_o3, differences = 1, lag = 12)
adf.test(data_train_sarima_ds_o3)
```

Dari hasil diatas bisa disimpulkan bahwa data belum stationer karena
nilai p-value \> 0,05 yaitu sebesar 0.3444.

#### b. Mengidentifikasi Diferensi non-musiman order 1

```{r}
data_train_sarima_dss_o3 <- diff(data_train_sarima_ds_o3, differences = 1)
adf.test(data_train_sarima_dss_o3)
```

Dari hasil diatas bisa disimpulkan bahwa data sudah stationer karena
nilai p-value \< 0,05 yaitu sebesar 0,01.


### iii. Mengidentifikasi kemungkinan model yang tepat

```{r}
par(mfrow = c(2,1))
acf(data_train_sarima_dss_o3, lag.max = 36)
pacf(data_train_sarima_dss_o3, lag.max = 36)
```

```{r}
data_train_sarima_dss_o3
```

### iv. Fit Model

Menentukan model prediksi yang terbaik yang dapat dilihat dari nilai
performansi Akaike Information Criteria (AIC) dan nilai signifikan
(p-value). Model yang lebih baik akan memiliki nilai AIC yang lebih
rendah

#### a. Fit Model 1



```{r}
# Fit Model 1
fitmodel1_o3 <- Arima (data_train_sarima_dss_o3,
                    order = c(2,2,1),
                    seasonal = c(2,0,3),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel1_o3)
checkresiduals(fitmodel1_o3)
ggtsdisplay(fitmodel1_o3$residuals)
summary(fitmodel1_o3)
```

```{r}
Box.test(residuals(fitmodel1_co), lag = 12, type = "Ljung-Box")
```

Secara keseluruhan dari model belum memenuhi taraf signifiksi dengan nilai
p-value 0.05127 dimana nilai signifikan \> 0,05 dan nilai AIC =
462.37. Sekarang kita akan lakukan fit model yang kedua dengan tujuan
untuk mendapatkan nilai yang lebih baik.

#### b. Fit Model 2

```{r}
# Fit Model 2
fitmodel2_o3 <- Arima (data_train_sarima_dss_o3,
                    order = c(2,2,1),
                    seasonal = c(3,0,2),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel2_o3)
checkresiduals(fitmodel2_o3)
ggtsdisplay(fitmodel2_o3$residuals)
summary(fitmodel2_o3)
```

```{r}
Box.test(residuals(fitmodel2_o3), lag = 12, type = "Ljung-Box")
```

Berdasarkan fit model yang ke 2 didapatkan bahwa secara keseluruhan
model masih belum memenuhi tingkat signifikan dengan nilai p-value 0.05246 dimana nilai
signifikan \< 0,05 dan nilai AIC 462.39. Kita akan lanjutkan melakukan
fit model yang ke 3.

#### c. Fit Model 3

```{r}
# Fit Model 3
fitmodel3_o3 <- Arima (data_train_sarima_dss_o3,
                    order = c(2,2,1),
                    seasonal = c(3,0,3),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel3_o3)
checkresiduals(fitmodel3_o3)
ggtsdisplay(fitmodel3_o3$residuals)
summary(fitmodel3_o3)
```

```{r}
Box.test(residuals(fitmodel3_o3), lag = 12, type = "Ljung-Box")
```

Berdasarkan fit model yang ke 3 didapatkan bahwa secara keseluruhan
model sudah signifikan dengan nilai p-value 0.0492 dimana nilai
signifikan \< 0,05 dan nilai AIC = 464.29.

#### d. Menentukan model terbaik dengan auto.arima

```{r}
# Menentukan model terbaik
modelautoarima_o3 <- auto.arima(
  data_train_sarima_dss_o3,
  stepwise = FALSE,
  approximation = FALSE,
  trace = TRUE)
modelautoarima_o3
```

```{r}
Box.test(residuals(modelautoarima_o3), lag = 12, type = "Ljung-Box")
```

#### e. Fit Model 4
```{r}
# Fit Model 4
fitmodel4_o3 <- Arima (data_train_sarima_dss_co,
                    order = c(0,0,1),
                    seasonal = c(1,0,3),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel4_o3)
checkresiduals(fitmodel4_o3)
ggtsdisplay(fitmodel4_o3$residuals)
summary(fitmodel4_o3)
```

```{r}
Box.test(residuals(fitmodel4_co), lag = 12, type = "Ljung-Box")
```
Berdasarkan fit model yang ke 4 didapatkan bahwa model ini juga belum
memenuhi tingkat signifikan dengan nilai p-value 0.09434 dimana nilai
signifikan \> 0,05 dan nilai AIC = 371.07.

#### f. Fit Model 5
```{r}
# Fit Model 5
fitmodel5_o3 <- Arima (data_train_sarima_dss_o3,
                    order = c(4,0,1),
                    seasonal = c(1,0,3),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel5_o3)
checkresiduals(fitmodel5_o3)
ggtsdisplay(fitmodel5_o3$residuals)
summary(fitmodel5_o3)
```

```{r}
Box.test(residuals(fitmodel5_o3), lag = 12, type = "Ljung-Box")
```
Berdasarkan fit model yang ke 5 didapatkan bahwa model ini juga belum
memenuhi tingkat signifikan dengan nilai p-value 0.1413 dimana nilai
signifikan \> 0,05 dan nilai AIC = 450.97.



```{r}
hasil_df_o3 <- data.frame(
  id = c(1:6),
  Model = c("Model1(2,2,1)(2,0,3)", "Model2(2,2,1)(3,0,2)", "Model3(2,2,1)(3,0,3)", "Model4(0,0,1)(1,0,3)", "Model5(4,0,1)(1,0,3)","AutoArima(0,0,0)(0,0,1)"),
  AIC = c(fitmodel1_o3$aic, fitmodel2_o3$aic, fitmodel3_o3$aic, fitmodel4_o3$aic, fitmodel5_o3$aic, modelautoarima_o3$aic),
  BIC = c(fitmodel1_o3$bic, fitmodel2_o3$bic, fitmodel3_o3$bic, fitmodel4_o3$bic, fitmodel5_o3$aic, modelautoarima_o3$bic),
   stringsAsFactors = FALSE
)
hasil_df_o3
```

Berdasarkan modelautoarima didapatkan model (0,0,0)(0,0,1) dengan nilai
AIC = 445.72.Sedangkan dari kelima model hanya model ketiga yang memenuhi 
taraf signifikasi dibawah 0.05 dimana model memiliki nilai AIC sebesar = 464.2942.
Sehingga hal ini menunjukkan model yang memiliki perfomansi terbaik yaitu model
dari AutoArima dengan nilai AIC sebesar 445.72


### v. Forecasting dengan data latih

```{r}
# Menggunakan model AutoArima
fcast_o3 <- forecast(modelautoarima_o3, h=12)
fcast_o3
autoplot(fcast_o3)
```
```{r}
# Menggunakan model fitmodel3
fcast_o3_2 <- forecast(fitmodel3_o3, h=12)
fcast_o3_2
autoplot(fcast_o3_2)
```


```{r}
# membuat prediksi untuk data uji dengan menggunakan model terbaik
predictSarima_o3 <- predict(fcast_o3, data_test_sarima_o3)
autoplot(predictSarima_o3)
```

```{r}
# visualisasi hasil forecast dari model multiplicative
data_test_sarima_o3 %>% 
  autoplot()+
  autolayer(modelautoarima_o3$fitted, series = "Auto-Arima(0,0,0)(0,0,1)")+
  autolayer(data_test_sarima_o3, series = "data test") +
  autolayer(fitmodel3_o3$fitted, series = "Model-3(2,2,1)(3,0,3)")+
  autolayer(predictSarima_o3$mean, series = "forecast")
```

### vi. Evaluasi Model

```{r}
# Mean squared error (MSE)
MSESarima_o3 <- mean((data_test_sarima_o3 - predictSarima_o3$mean)^2)
MSESarima_o3
```

```{r}
# Root mean squared error (RMSE)
RMSESarima_o3 <- sqrt(MSESarima_o3)
RMSESarima_o3
```

```{r}
# Mean absolute error (MAE)
MAESarima_o3 <- mean(abs(data_test_sarima_o3 - predictSarima_o3$mean))
MAESarima_o3
```

```{r}
# Mean absolute percentage error (MAPE)
MAPESarima_o3 <- mean(abs(data_test_sarima_o3 - predictSarima_o3$mean) / data_test_sarima_o3)
MAPESarima_o3
```

## e. Model Prediksi CO

Pengujian akan dilakukan pada data df_dki_4 dengan menggunakan uji
Augmented Dickey-Fuller (ADF) dan Kwiatkowski Phillips Schmidt Shin
(KPSS). ADF Test Test ini digunakan untuk memahami apakah deret tersebut
stationer atau tidak. Ada 2 hipotesis yang bisa dikembangkan. H0: deret
waktu tidak stationer dan memiliki beberapa struktur tergantung waktu
*H1: deret waktu stationer dan tidak memiliki beberapa struktur
tergantung waktu* dengan nilai p-value \< 0,05 sehingga HO ditolak, H1
diterima

KPSS test H0 dan H1 untuk uji KPSS berlawanan dengan uji ADF, sehingga
hipotesis dalam KPSS adalah H0: deret tren stationer *H1: deret tren
tidak stationer* dengan nilai p-value \< 0,05 sehingga HO diterima, H1
ditolak

```{r}
adf.test(df_dki_4$no2)
```

```{r}
kpss.test(df_dki_4$no2, null = "Level")
```

```{r}
#differensiasi data_so2 pada stasiun DKI4
df_dki_4_diff_no2 <- diff(df_dki_4$no2)
#dropna dari data yang sudah di-differensiasi
df_dki_4_diff_no2 <- df_dki_4_diff_no2[!is.na(df_dki_4_diff_no2)]
```

```{r}
#plot data yang sudah di-differensiasi dan di-dropna
ggplot(data.frame(date = 1:length(df_dki_4_diff_no2), value = df_dki_4_diff_no2), aes(x = date, y = value)) +
  geom_line(color = "blue") +
  ggtitle("Stationary timeseries")+
  theme(plot.title = element_text(hjust = 0.5))+
  scale_x_continuous(name = "Hari",
                     breaks = seq(0, length(df_dki_4_diff_no2), by = 365))+ #periode 365 hari
  scale_y_continuous(name = "Nilai")+
  theme(axis.text.x=element_text(angle=60,hjust=1))+
  theme_minimal()
```

Berdasarkan hasil kedua uji ADF dan KPSS bisa disimpulkan nilai p-value
\< 0,05, sehingga bisa disimpulkan bahwa data deret waktu sudah
stationer. Begitu juga dengan hasil visualiasi uji stationer bisa
dilihat bahwa tidak terlihat tren apapun atau perubahan yang jelas dalam
varians sehingga deret waktu sudah stationer.

### i. Data Dekomposisi

```{r}
decom_ts_no2 <- ts(data = Data.SPKU$no2, start = c(2016,1), end = c(2021,12), frequency = 12)
```

```{r}
# Classical Decomposition
decom_ts_no2 %>% decompose(type = "multiplicative") %>%
  autoplot() + xlab("Year") +
  ggtitle("Multiplicative Decomposition of NO2")
```

```{r}
decom_ts_no2 %>% decompose(type = "additive") %>%
  autoplot() + xlab("Year") +
  ggtitle("Additive Decomposition of NO2")
```

```{r}
ts_decom_no2 <- decompose(decom_ts_no2)
```

```{r}
ts_decom_table_no2 <- data.frame(seasonal = ts_decom_co$seasonal, trend = ts_decom_no2$trend, random = ts_decom_no2$random)
ts_decom_table_no2 <- na.omit(ts_decom_table_no2)
descr(ts_decom_table_no2)
head(ts_decom_table_no2)
```

```{r}
ts_decom_no2$seasonal
```

```{r}
plot(ts_decom_no2$seasonal)
```

```{r}
ts_decom_no2$figure
```

```{r}
plot(ts_decom_no2$figure,
     type = 'b',
     xlab = 'Month',
     ylab = 'Seasonality Index',
     col = 'blue',
     las = 2
)
```

```{r}
#adjustment decomposition data
ts_decom_adj_no2 <- decom_ts_no2 - ts_decom_no2$seasonal
plot(ts_decom_adj_no2)
```

```{r}
ts_decom_adj_no2
```

```{r}
descr(ts_decom_adj_no2)
```

```{r}
str(ts_decom_adj_no2)
```

```{r}
df_data_no2 <- as.data.frame(ts_decom_adj_no2)
df_data_no2
```



```{r}
# Konversi data menjadi data time series menggunakan data dekomposisi time series 
dataset_no2 <- decom_ts_no2
plot(dataset_no2)
ggtsdisplay(dataset_no2)
```

```{r}
BoxCox.lambda(dataset_no2)
```

```{r}
# Membagi data menjadi data latih dan data uji
data_train_sarima_no2 <- head(dataset_no2, 5*12) # ambil data 5 tahun 2016-2020
data_test_sarima_no2 <- tail(dataset_no2, length(dataset_no2)-length(data_train_sarima_no2)) #ambil data 1 tahun terakhir
data_train_sarima_no2 %>% 
  decompose() %>% 
  autoplot()
```

```{r}
plot(data_train_sarima_no2)
```

```{r}
length(data_train_sarima_no2)
length(data_test_sarima_no2)
```

### ii. Mengidentifikasi Diferensi

#### a. Mengidentifikasi Diferensi musiman order 1

```{r}
data_train_sarima_ds_no2 <- diff(data_train_sarima_no2, differences = 1, lag = 12)
adf.test(data_train_sarima_ds_no2)
```

Dari hasil diatas bisa disimpulkan bahwa data belum stationer karena
nilai p-value \> 0,05 yaitu sebesar 0.1433.

#### b. Mengidentifikasi Diferensi non-musiman order 1

```{r}
data_train_sarima_dss_no2 <- diff(data_train_sarima_ds_no2, differences = 1)
adf.test(data_train_sarima_dss_no2)
```

Dari hasil diatas bisa disimpulkan bahwa data sudah stationer karena
nilai p-value \< 0,05 yaitu sebesar 0.04407.


### iii. Mengidentifikasi kemungkinan model yang tepat

```{r}
par(mfrow = c(2,1))
acf(data_train_sarima_dss_no2, lag.max = 36)
pacf(data_train_sarima_dss_no2, lag.max = 36)
```

```{r}
data_train_sarima_dss_no2
```

### iv. Fit Model

Menentukan model prediksi yang terbaik yang dapat dilihat dari nilai
performansi Akaike Information Criteria (AIC) dan nilai signifikan
(p-value). Model yang lebih baik akan memiliki nilai AIC yang lebih
rendah

#### a. Fit Model 1



```{r}
# Fit Model 1
fitmodel1_no2 <- Arima (data_train_sarima_dss_no2,
                    order = c(1,1,0),
                    seasonal = c(0,0,1),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel1_no2)
checkresiduals(fitmodel1_no2)
ggtsdisplay(fitmodel1_no2$residuals)
summary(fitmodel1_no2)
```

```{r}
Box.test(residuals(fitmodel1_no2), lag = 12, type = "Ljung-Box")
```


Secara keseluruhan dari model telah memenuhi tingkat signifikasi dimana nilai
p-value 0.00639 dimana nilai signifikan \< 0,05 dan nilai AIC =
299.65. Sekarang kita akan lakukan fit model yang kedua dengan tujuan
untuk mendapatkan nilai yang lebih baik.

#### b. Fit Model 2

```{r}
# Fit Model 2
fitmodel2_no2 <- Arima (data_train_sarima_dss_no2,
                    order = c(2,2,0),
                    seasonal = c(1,0,2),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel2_no2)
checkresiduals(fitmodel2_no2)
ggtsdisplay(fitmodel2_no2$residuals)
summary(fitmodel2_no2)
```

```{r}
Box.test(residuals(fitmodel2_no2), lag = 12, type = "Ljung-Box")
```

Berdasarkan fit model yang ke 2 didapatkan bahwa secara keseluruhan
model sudah signifikan dengan nilai p-value 0.02932 dimana nilai
signifikan \< 0,05 dan nilai AIC 315.69. Kita akan lanjutkan melakukan
fit model yang ke 3.

#### c. Fit Model 3

```{r}
# Fit Model 3
fitmodel3_no2 <- Arima (data_train_sarima_dss_no2,
                    order = c(2,2,0),
                    seasonal = c(2,0,2),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel3_no2)
checkresiduals(fitmodel3_no2)
ggtsdisplay(fitmodel3_no2$residuals)
summary(fitmodel3_no2)
```

```{r}
Box.test(residuals(fitmodel3_no2), lag = 12, type = "Ljung-Box")
```

Berdasarkan fit model yang ke 3 didapatkan bahwa model telah 
memenuhi taraf signifikasi dengan nilai p-value 0.01343 dimana nilai
signifikan \< 0,05 dan nilai AIC = 317.69.

#### d. Menentukan model terbaik dengan auto.arima

```{r}
# Menentukan model terbaik
modelautoarima_no2 <- auto.arima(
  data_train_sarima_dss_no2,
  stepwise = FALSE,
  approximation = FALSE,
  trace = TRUE)
modelautoarima_no2
```

```{r}
Box.test(residuals(modelautoarima_no2), lag = 12, type = "Ljung-Box")
```

#### e. Fit Model 4
```{r}
# Fit Model 4
fitmodel4_no2 <- Arima (data_train_sarima_dss_no2,
                    order = c(1,0,1),
                    seasonal = c(1,0,3),
                    lambda = NULL,
                    include.constant = TRUE)
coeftest(fitmodel4_no2)
checkresiduals(fitmodel4_no2)
ggtsdisplay(fitmodel4_no2$residuals)
summary(fitmodel4_no2)
```

```{r}
Box.test(residuals(fitmodel4_no2), lag = 12, type = "Ljung-Box")
```
Berdasarkan fit model yang ke 4 didapatkan bahwa secara keseluruhan
model sudah signifikan dengan nilai p-value 0.04635 dimana nilai
signifikan \< 0,05 dan nilai AIC = 288.41.


```{r}
hasil_df_no2 <- data.frame(
  id = c(1:5),
  Model = c("Model1(1,1,0)(0,0,1)", "Model2(2,2,0)(1,0,2)", "Model3(2,2,0)(2,0,2)", "Model4(1,0,1)(1,0,3)","AutoArima(0,0,0)(1,0,1)"),
  AIC = c(fitmodel1_no2$aic, fitmodel2_no2$aic, fitmodel3_no2$aic, fitmodel4_no2$aic, modelautoarima_no2$aic),
  BIC = c(fitmodel1_no2$bic, fitmodel2_no2$bic, fitmodel3_no2$bic, fitmodel4_no2$bic, modelautoarima_no2$bic),
   stringsAsFactors = FALSE
)
hasil_df_no2
```

Berdasarkan modelautoarima didapatkan model (0,0,0)(1,0,1) dengan nilai
AIC = 280.23. Sehingga dapat disimpulkan bahwa performa fitmodel1 dengan
nilai AIC = 299.65, fitmodel2 dengan nilai AIC = 315.69 dan fitmodel3
dengan nilai AIC = 317.69, dan fitmodel4 dengan nilai AIC 288.41.
Berdasarkan kelima model tersebut, maka perfomansi model AutoArima
yang terbaik yaitu model (0,0,0)(1,0,1) dengan nilai AIC sebesar 280.28
dan nilai p-value untuk keseluruhan signitifkan.



### v. Forecasting dengan data latih

```{r}
# Menggunakan fitmodel4
fcast_no2 <- forecast(modelautoarima_no2, h=12)
fcast_no2
autoplot(fcast_no2)
```
```{r}
# Menggunakan fitmodel4
fcast_no2_2 <- forecast(fitmodel4_no2, h=12)
fcast_no2_2
autoplot(fcast_no2_2)
```


```{r}
# membuat prediksi untuk data uji dengan menggunakan model terbaik
predictSarima_no2 <- predict(fcast_no2, data_test_sarima_no2)
autoplot(predictSarima_no2)
```

```{r}
# visualisasi hasil forecast dari model multiplicative
data_test_sarima_no2 %>% 
  autoplot()+
  autolayer(modelautoarima_no2$fitted, series = "Auto-Arima(0,0,3)(1,0,0)")+
  autolayer(data_test_sarima_no2, series = "data test") +
  autolayer(fitmodel1_no2$fitted, series = "Model-1(1,1,0)(0,0,1)")+
  autolayer(fitmodel2_no2$fitted, series = "Model-2(2,2,0)(1,0,2)")+
  autolayer(fitmodel3_no2$fitted, series = "Model-3(2,2,0)(2,0,2)")+
  autolayer(fitmodel4_no2$fitted, series = "Model-4(1,0,1)(1,0,3)")+
  autolayer(predictSarima_no2$mean, series = "forecast")
```

### vi. Evaluasi Model

```{r}
# Mean squared error (MSE)
MSESarima_no2 <- mean((data_test_sarima_no2 - predictSarima_no2$mean)^2)
MSESarima_no2
```

```{r}
# Root mean squared error (RMSE)
RMSESarima_no2 <- sqrt(MSESarima_no2)
RMSESarima_no2
```

```{r}
# Mean absolute error (MAE)
MAESarima_no2 <- mean(abs(data_test_sarima_no2 - predictSarima_no2$mean))
MAESarima_no2
```

```{r}
# Mean absolute percentage error (MAPE)
MAPESarima_no2 <- mean(abs(data_test_sarima_no2 - predictSarima_no2$mean) / data_test_sarima_no2)
MAPESarima_no2
```
